{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 전처리 코드\n",
    "##### NEWS_DIRECTORY, 즉 경로만 수정하면 문제 없이 user filtering 이전/이후(raw/not raw) 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import sample\n",
    "# import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "\n",
    "NEWS_DIRECTORY = './Adressa_4w'\n",
    "dir_list = ['history','train','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make_user_news_data    all_start_time: 24-11-13 20:20:36\n",
      "\n",
      "\n",
      "\n",
      "Start preprocessing    preprocessing start_time: 24-11-13 20:20:36\n",
      "\n",
      "\n",
      "[history] 1 / 3     위치 :  ./Adressa_4w\\history\n",
      "\n",
      "1/26     파일:./Adressa_4w\\history\\20170122 #start_time: 11-13 20:20:36 #Time: 1485039602.0\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Big Data Science LAB\\anaconda3\\envs\\adressa_preprocess\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 1. user filtering을 위해 body를 생성하는 코드\n",
    "\n",
    "\n",
    "def parse_time(timestamp):\n",
    "    return datetime.fromtimestamp(float(timestamp)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def str_to_timestamp(string):\n",
    "    return datetime.timestamp(datetime.strptime(string,'%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "\n",
    "\"\"\" Step 1. make_user_news_data 정의\n",
    "\"\"\"\n",
    "\n",
    "### def make_user_news_data():\n",
    "print()\n",
    "print('Make_user_news_data',end='    ')\n",
    "print('all_start_time:',time.strftime('%y-%m-%d %H:%M:%S'))\n",
    "print()\n",
    "print()\n",
    "start = time.time()\n",
    "first_execution = True\n",
    "def make_user_news_dic(body):\n",
    "    global user_dic\n",
    "    global user_cnt\n",
    "    global news_cnt\n",
    "    global news_dic\n",
    "    global index\n",
    "    global behaviors_list\n",
    "    global filter1_cnt\n",
    "    global behaviors_user_filter_cnt\n",
    "    global time_error_cnt\n",
    "    global first_execution\n",
    "    # 내가 추가한 것\n",
    "    global time_limit_list\n",
    "    \n",
    "\n",
    "    ### 유효한 뉴스 데이터만 취급. 이로써, 뉴스 데이터는 시작부터 필터링 됨\n",
    "    filter_list = [\"time\", \"publishtime\",\n",
    "                \"title\", \"userId\",\"url\", \"canonicalUrl\"]\n",
    "    if all(filter in body.keys() for filter in filter_list):\n",
    "        ### 처음 실행 때는 user_filter가 정의되지 않아 이를 제하고 실행하게 함\n",
    "        if first_execution:\n",
    "            pass\n",
    "        else:\n",
    "            if user_filter_dic.get(body['userId'],False):\n",
    "                behaviors_user_filter_cnt += 1\n",
    "                return\n",
    "        \n",
    "        ### news_dic 만들기\n",
    "        body['publishtime'] = body['publishtime'].split('.')[0].replace('T',' ')\n",
    "        body['time'] = parse_time(body['time'])\n",
    "        \n",
    "        ### 시간 역행 필터링\n",
    "        if str_to_timestamp(body['time'])-str_to_timestamp(body['publishtime']) < 0:\n",
    "            time_error_cnt += 1\n",
    "            return\n",
    "        \n",
    "        ### body에 뉴스 데이터 추가\n",
    "            ### 1) Url이 존재하지 않는 경우\n",
    "        if body['canonicalUrl'] not in news_dic.keys():\n",
    "            news_id = 'N'+str(news_cnt)\n",
    "            news_dic[body['canonicalUrl']] = [news_id,body['publishtime'],body['title']]\n",
    "            news_dic[body['canonicalUrl']].append([body['time']])\n",
    "            news_cnt += 1\n",
    "            # news_df = news_df.append({'news_id':news_id,'url':body['canonicalUrl'],'publish_time':body['publishtime'],'clicked_times':body['time'],'title':body['title']},ignore_index=True)\n",
    "            if 'category1' in body.keys():\n",
    "                news_dic[body['canonicalUrl']].append(body['category1'])\n",
    "            else:\n",
    "                news_dic[body['canonicalUrl']].append(\"\")\n",
    "            # if news_cnt == 10:\n",
    "            #     break\n",
    "        \n",
    "            ### 2) 이미 Url이 존재하는 경우 \n",
    "        else:\n",
    "            news_id = news_dic[body['canonicalUrl']][0]\n",
    "            news_dic[body['canonicalUrl']][3].append(body['time'])\n",
    "            # target_news_index = int(news_dic[body['canonicalUrl']][1:]) - 1\n",
    "            # news_id = news_df.loc[target_news_index]['news_id']\n",
    "            # total_click = news_df.loc[target_news_index]['clicked_times']+',' + body['time']\n",
    "            # news_df.at[target_news_index,'clicked_times'] = total_click\n",
    "        \n",
    "        ### news_dic 만들기 끝. 여기부터는  user_dic 만들기\n",
    "        add_click = news_id+ ','+body['publishtime']+ ','+body['time']\n",
    "            \n",
    "            ### 1) userId가 user_dic에 없는 경우: history, train, test 중 현재 파일의 폴더에 따라 해당 index에 데이터 저장\n",
    "        if body['userId'] not in user_dic.keys():\n",
    "            user_id = 'U'+str(user_cnt)\n",
    "            user_dic[body['userId']] =[user_id]\n",
    "            user_dic[body['userId']].append([]) # history\n",
    "            user_dic[body['userId']].append([]) # train\n",
    "            user_dic[body['userId']].append([]) # test\n",
    "            user_dic[body['userId']][index].append([add_click]) # 각 폴더 데이터 body['userId']에 추가하는 부분; ex) index == 1이면 history\n",
    "            user_cnt += 1\n",
    "\n",
    "        user_dic[body['userId']][index].append([add_click])\n",
    "            \n",
    "            ### 2) train의 경우,해당 유저의 history 뉴스들을 가져와 history로 저장\n",
    "        if data_type == \"train\":\n",
    "            user_id = user_dic[body['userId']][0]\n",
    "            history_list = list(set([j.split(',')[0] for i in user_dic[body['userId']][1] for j in i ]))\n",
    "            write_line = user_id+'\\t'+body['time'] + '\\t' + ' '.join(history_list) + '\\t'+news_id+'-1'\n",
    "            behaviors_list.append(write_line)\n",
    "\n",
    "            # target_user_index = int(user_dic[body['userId']][1:])-1\n",
    "            # total_click = user_df.loc[target_user_index][data_type]+'\\t'+add_click\n",
    "            # user_df.at[target_user_index,data_type] = total_click\n",
    "            \n",
    "            ### 3) test의 경우 history, train의 뉴스들을 모두 가져와 user history로 저장\n",
    "        elif data_type == \"test\":\n",
    "            user_id = user_dic[body['userId']][0]\n",
    "            \"\"\" 내 주석: history_list에는 history와 train 모두 사용 \"\"\"\n",
    "            history_list = list(set(\n",
    "                                    [j.split(',')[0] for i in user_dic[body['userId']][1] for j in i ]\n",
    "                                    + [j.split(',')[0] for i in user_dic[body['userId']][2] for j in i ]))\n",
    "            write_line = user_id+'\\t'+body['time'] + '\\t' + ' '.join(history_list) + '\\t'+news_id+'-1'\n",
    "            behaviors_list.append(write_line)\n",
    "\n",
    "    # 유효하지 않은 뉴스 수 계산\n",
    "    else:\n",
    "        filter1_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Step 2. make_user_news_dic 실행하여 폴더마다 news/behaviors(raw).tsv 생성\n",
    "### make_user_news_dic 정의 끝. 이제는 make_user_news_dic 실행하여 user.tsv 생성\n",
    "########### user_behaviors filtering & news.tsv, user_behaviors.tsv 생성\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "user_cnt = 1\n",
    "news_cnt = 1\n",
    "user_dic = {}\n",
    "behavior_cnt = 0\n",
    "total_cnt = 1\n",
    "\n",
    "filter1_cnt = 1  ### 더미 데이터 제거\n",
    "behaviors_user_filter_cnt = 1\n",
    "time_error_cnt = 1\n",
    "\n",
    "# start preprocessing\n",
    "print()\n",
    "print('Start preprocessing',end='    ')\n",
    "print('preprocessing start_time:',time.strftime('%y-%m-%d %H:%M:%S'))\n",
    "print()\n",
    "print()\n",
    "\n",
    "A = 1000000\n",
    "# history, train, test 별 time_limit 설정\n",
    "time_limit_list = [str_to_timestamp(\"2017-02-05 08:00:02\"), str_to_timestamp(\"2017-02-12 08:00:02\"), str_to_timestamp(\"2017-02-19 08:00:02\")]\n",
    "for data_type in dir_list:\n",
    "    # news_df = pd.DataFrame(columns = ['news_id','publish_time','category','clicked_times','title','url'])\n",
    "    news_dic = {}\n",
    "    behaviors_list= []\n",
    "    length = len(dir_list)\n",
    "    index += 1\n",
    "    print(f'[{data_type}] {index} / {length}',end='     ')\n",
    "        # print('[missed data_type]', cnt)\n",
    "    data_folder = os.path.join(NEWS_DIRECTORY, data_type)\n",
    "    print(f'위치 :  {data_folder}')\n",
    "    print()\n",
    "    index2 = 1\n",
    "    \n",
    "    ### 각 raw data 파일 (.file)마다 for문 적용\n",
    "    for news in os.listdir(data_folder):\n",
    "        start2 = time.time()\n",
    "        if news.endswith('.tsv') or news.endswith('.npy'):\n",
    "            continue\n",
    "        news_file = os.path.join(data_folder,news)\n",
    "        # 진행 중인 파일 print\n",
    "        print(f'{index2}/{len(os.listdir(data_folder))}     파일:{news_file}',end=' #')\n",
    "        print('start_time:',time.strftime('%m-%d %H:%M:%S'),end=' #')\n",
    "\n",
    "\n",
    "        ### 파일을 열어 각 줄 (body)마다 make_user_news_dic 실행\n",
    "        index2 += 1\n",
    "        file1 = open(news_file,'r')\n",
    "        while True:\n",
    "            total_cnt += 1\n",
    "            line = file1.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            body = json.loads(line)\n",
    "            \n",
    "            ###################### time_limit 적용 부분            \n",
    "            # body['time'] = parse_time(body['time'])\n",
    "            # Time = str_to_timestamp(body['time'])\n",
    "            # print(\"Time:\", Time)\n",
    "            # for i in range(100):\n",
    "            #     print(\"yes\")\n",
    "            # sys.exit()\n",
    "            # if index == 0: # 2017-02-05 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            # elif index == 1: # 2017-02-05 08:00:02 부터 2017-02-12 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index-1] > Time or time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            # elif index == 2: # 2017-02-12 08:00:02 부터 2017-02-19 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index-1] > Time or time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            \n",
    "            \n",
    "            # print(body.keys())\n",
    "\n",
    "            make_user_news_dic(body)\n",
    "\n",
    "        print('elapsed_time:',round(time.time()-start2,1))\n",
    "        # a = len(user_dic)\n",
    "        # if a >= A:\n",
    "        #     print(f\"A: {A}, a: {a} \\n\")\n",
    "        #     exit()\n",
    "            \n",
    "        # print(f\"A: {A}, a: {a} \\n\")\n",
    "        # A = a\n",
    "    \n",
    "    \n",
    "    ### 유저 필터링 전에 news/behaviors(raw).tsv 생성\n",
    "    with open(os.path.join(data_folder,'news(raw).tsv'),'w',encoding='UTF-8') as wf:\n",
    "        for key in news_dic.keys():\n",
    "            wf.write(news_dic[key][0]+'\\t'+news_dic[key][1]+'\\t'+news_dic[key][2]+'\\t'+','.join(news_dic[key][3])+'\\t'+news_dic[key][4]+'\\n')\n",
    "    with open(os.path.join(data_folder,'behaviors(raw).tsv'),'w',encoding='UTF-8') as wf:\n",
    "        for line in behaviors_list:\n",
    "            wf.write(line+'\\n')\n",
    "    behavior_cnt += len(behaviors_list)\n",
    "    print(f\"{data_type} behavior_cnt\",len(behaviors_list))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### user_dic 간단 체크\n",
    "print()\n",
    "print(len(user_dic))\n",
    "print()\n",
    "print()        \n",
    "for key, value in itertools.islice(user_dic.items(), 10):\n",
    "    print(f\"{key}\")\n",
    "print()\n",
    "print()\n",
    "# print(\"exit\")\n",
    "# exit()\n",
    " \n",
    "        \n",
    "########## user filtering & user.tsv\n",
    "\"\"\"Step 3. user(raw).tsv 생성\"\"\"\n",
    "\n",
    "\n",
    "### 각 구간 별 클릭 없는 유저 제거 리스트\n",
    "user_filter = []   \n",
    "user_filter2_cnt = 1\n",
    "user_filter3_cnt = 1\n",
    "user_time_list = []\n",
    "### user filtering 전 user(raw).tsv 생성\n",
    "with open(os.path.join(NEWS_DIRECTORY,'user(raw).tsv'),'w',encoding='UTF-8') as wf2:\n",
    "    for key in tqdm(user_dic.keys()):\n",
    "        ### history, train, test의 클릭 수 합이 20보다 적으면 필터링\n",
    "        if len(user_dic[key][1]) + len(user_dic[key][2]) + len(user_dic[key][3]) < 20: # 3가지 \n",
    "            user_filter2_cnt += 1\n",
    "            user_filter.append(key)\n",
    "\n",
    "        # history, train, test 중 하나라도 클릭 수가 0이면 필터링\n",
    "        elif (len(user_dic[key][1]) == 0) or (len(user_dic[key][2]) == 0) or (len(user_dic[key][3]) == 0):\n",
    "            user_filter3_cnt += 1\n",
    "            user_filter.append(key)\n",
    "            \n",
    "        ### 파일 생성\n",
    "        else:\n",
    "            writeline = user_dic[key][0]+'\\t'\n",
    "            for click in user_dic[key][1]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\t'\n",
    "            for click in user_dic[key][2]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\t'\n",
    "            for click in user_dic[key][3]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\n'\n",
    "            wf2.write(writeline)\n",
    "#     news_df.to_csv(os.path.join(data_folder,'news.tsv'),index=False)\n",
    "# user_df.to_csv(os.path.join(NEWS_DIRECTORY,'user.tsv'),index=False)\n",
    "print()\n",
    "print(user_filter2_cnt)\n",
    "print(user_filter3_cnt)\n",
    "print()\n",
    "print()\n",
    "print('total_elapsed_time:',round(time.time()-start,1))\n",
    "user_filter = set(user_filter)\n",
    "user_filter_dic = {x:True for x in user_filter}  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"Step 4. make_user_news_dic 재실행하여 user filtering 적용\n",
    "   이때, 최종본인 news/behaviors.tsv 생성\"\"\"\n",
    "        \n",
    "        \n",
    "\"\"\" make_user_news_dic 실행 끝.\n",
    "    이제는 얻어진 user_filter_dic을 사용하여 make_user_news_dic 다시 생성\n",
    "    뒤는 주석 user.tsv 부분만 다름\"\"\"      \n",
    "\n",
    "\n",
    "########### user_behaviors filtering & news.tsv, user_behaviors.tsv\n",
    "index = 0\n",
    "\n",
    "user_cnt = 1\n",
    "news_cnt = 1\n",
    "user_dic = {}\n",
    "behavior_cnt = 0\n",
    "total_cnt = 1\n",
    "\n",
    "filter1_cnt = 1  ### 더미 데이터 제거\n",
    "behaviors_user_filter_cnt = 1\n",
    "time_error_cnt = 1\n",
    "\n",
    "# start preprocessing:\n",
    "print()\n",
    "print('Start preprocessing',end='    ')\n",
    "print('preprocessing start_time:',time.strftime('%y-%m-%d %H:%M:%S'))\n",
    "print()\n",
    "print()\n",
    "\n",
    "for data_type in dir_list:\n",
    "    # news_df = pd.DataFrame(columns = ['news_id','publish_time','category','clicked_times','title','url'])\n",
    "    news_dic = {}\n",
    "    behaviors_list= []\n",
    "    length = len(dir_list)\n",
    "    index += 1\n",
    "    print(f'[{data_type}] {index} / {length}',end='     ')\n",
    "        # print('[missed data_type]', cnt)\n",
    "    data_folder = os.path.join(NEWS_DIRECTORY, data_type)\n",
    "    print(f'위치 :  {data_folder}')\n",
    "    print()\n",
    "    index2 = 1\n",
    "    for news in os.listdir(data_folder):\n",
    "        start2 = time.time()\n",
    "        if news.endswith('.tsv') or news.endswith('.npy'):\n",
    "            continue\n",
    "        news_file = os.path.join(data_folder,news)\n",
    "        print(f'{index2}/{len(os.listdir(data_folder))}     파일:{news_file}',end=' #')\n",
    "        print('start_time:',time.strftime('%m-%d %H:%M:%S'),end=' #')\n",
    "\n",
    "\n",
    "        index2 += 1\n",
    "        file1 = open(news_file,'r')\n",
    "        \n",
    "        \"\"\"first_execution False로 변경\"\"\"\n",
    "        first_execution = False \n",
    "        while True:\n",
    "            total_cnt += 1\n",
    "            line = file1.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            body = json.loads(line)\n",
    "            # print(body.keys())\n",
    "            \n",
    "            ###################### time_limit 적용 부분            \n",
    "            # body['time'] = parse_time(body['time'])\n",
    "            # Time = str_to_timestamp(body['time'])\n",
    "            # if index == 0: # 2017-02-05 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            # elif index == 1: # 2017-02-05 08:00:02 부터 2017-02-12 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index-1] > Time or time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            # elif index == 2: # 2017-02-12 08:00:02 부터 2017-02-19 08:00:02 이전까지만 적용\n",
    "            #     if time_limit_list[index-1] > Time or time_limit_list[index] < Time:\n",
    "            #         continue\n",
    "            \n",
    "            \"\"\"여기서 first_execution=False이므로, user filtering 재수행\"\"\"\n",
    "            make_user_news_dic(body)\n",
    "\n",
    "        print('elapsed_time:',round(time.time()-start2,1))\n",
    "\n",
    "\n",
    "    \"\"\"수행된 유저 필터링을 바탕으로 최종 news/behaviors.tsv 생성\"\"\"\n",
    "    with open(os.path.join(data_folder,'news.tsv'),'w',encoding='UTF-8') as wf:\n",
    "        for key in news_dic.keys():\n",
    "            wf.write(news_dic[key][0]+'\\t'+news_dic[key][1]+'\\t'+news_dic[key][2]+'\\t'+','.join(news_dic[key][3])+'\\t'+news_dic[key][4]+'\\n')\n",
    "    with open(os.path.join(data_folder,'behaviors.tsv'),'w',encoding='UTF-8') as wf:\n",
    "        for line in behaviors_list:\n",
    "            wf.write(line+'\\n')\n",
    "    behavior_cnt += len(behaviors_list)\n",
    "    print(f\"{data_type} behavior_cnt\",len(behaviors_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Step 4. 최종본인 user.tsv 생성\"\"\"\n",
    "\n",
    "\"\"\"수행된 유저 필터링을 바탕으로 최종 user.tsv 생성\"\"\"\n",
    "user_filter = []   ### 각 구간 별 클릭 없는 유저 제거\n",
    "user_filter2_cnt = 1\n",
    "user_filter3_cnt = 1\n",
    "user_time_list = []\n",
    "with open(os.path.join(NEWS_DIRECTORY,'user.tsv'),'w',encoding='UTF-8') as wf2:\n",
    "    for key in tqdm(user_dic.keys()):\n",
    "        if len(user_dic[key][1]) + len(user_dic[key][2]) + len(user_dic[key][3]) < 20:\n",
    "            user_filter2_cnt += 1\n",
    "            user_filter.append(key)\n",
    "\n",
    "        elif (len(user_dic[key][1]) == 0) or (len(user_dic[key][2]) == 0) or (len(user_dic[key][3]) == 0):\n",
    "            user_filter3_cnt += 1\n",
    "            user_filter.append(key)\n",
    "        else:\n",
    "            writeline = user_dic[key][0]+'\\t'\n",
    "            for click in user_dic[key][1]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\t'\n",
    "            for click in user_dic[key][2]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\t'\n",
    "            for click in user_dic[key][3]:\n",
    "                click = click[0]\n",
    "                writeline += click+';'\n",
    "                tmp = click.split(',')\n",
    "                user_time_list.append(str_to_timestamp(tmp[2])-str_to_timestamp(tmp[1]))\n",
    "            writeline.strip(';')\n",
    "            writeline += '\\n'\n",
    "            wf2.write(writeline)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"news_cnt:\",news_cnt)\n",
    "print(\"user_cnt\",user_cnt)\n",
    "print(\"behavior_cnt\",behavior_cnt)\n",
    "print(\"total_cnt\",total_cnt)\n",
    "print(\"filter1_cnt\",filter1_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total.news(raw).tsv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-12 18:15:22\n",
      "  user                 time                                   history    click\n",
      "0   U1  2017-02-10 08:00:02                            N1 N1560 N1794  N1895-1\n",
      "1   U2  2017-02-10 08:00:02  N2 N89 N68 N1100 N1103 N12 N1085 N109 N6  N1896-1\n",
      "2   U3  2017-02-10 08:00:02                                   N3 N582  N1897-1\n",
      "3   U4  2017-02-10 08:00:02        N1662 N1515 N1134 N4 N1725 N12 N16  N1898-1\n",
      "4   U5  2017-02-10 08:00:02                                   N630 N5  N1899-1\n",
      "  user                 time  \\\n",
      "5   U6  2017-02-10 08:00:02   \n",
      "6   U7  2017-02-10 08:00:03   \n",
      "7   U8  2017-02-10 08:00:03   \n",
      "8   U9  2017-02-10 08:00:03   \n",
      "9  U10  2017-02-10 08:00:03   \n",
      "\n",
      "                                             history    click  \n",
      "5                                           N1134 N6  N1900-1  \n",
      "6                                        N4 N36 N417  N1898-1  \n",
      "7                                             N22 N5  N1899-1  \n",
      "8                                                 N7  N1901-1  \n",
      "9  N939 N7 N1636 N417 N1528 N1515 N1134 N1819 N17...  N1901-1  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# 현재 Unix 타임스탬프를 연도, 날짜, 시간으로 변환\n",
    "timestamp = time.time()\n",
    "formatted_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(formatted_time)\n",
    "\n",
    "\n",
    "\n",
    "data_type = 'Adressa_4w'\n",
    "train_dir = f'C://Users//Big Data Science LAB//seongju//datasets//{data_type}/train'\n",
    "\n",
    "behaviors = pd.read_table(\n",
    "    os.path.join(train_dir,'behaviors.tsv'),\n",
    "    header=None,\n",
    "    names=['user', 'time', 'history', 'click'])\n",
    "\n",
    "print(behaviors[:5])\n",
    "print(behaviors[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이 생성되었습니다: ./Adressa_4w\\total_news(raw).tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 폴더 경로 설정\n",
    "NEWS_DIRECTORY = './Adressa_4w'\n",
    "dir_list = ['history','train','test']\n",
    "output_file = os.path.join(NEWS_DIRECTORY, 'total_news(raw).tsv')\n",
    "\n",
    "# 빈 데이터프레임 생성\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 각 폴더에서 'news(raw).tsv' 파일 읽기\n",
    "for folder in dir_list:\n",
    "    file_path = os.path.join(NEWS_DIRECTORY, folder, 'news(raw).tsv')\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path, sep='\\t', header=None)  # TSV 파일 불러오기\n",
    "        all_data = pd.concat([all_data, data], ignore_index=True)  # 데이터프레임에 추가\n",
    "\n",
    "# 컬럼 이름 지정 (기존 형식에 맞게 열의 이름을 부여)\n",
    "all_data.columns = ['index', 'date', 'title', 'timestamps', 'category']\n",
    "\n",
    "# 중복 제거: 'index' 컬럼을 기준으로 중복 제거 후, 첫 번째로 나타난 행 유지\n",
    "all_data = all_data.drop_duplicates(subset='index')\n",
    "\n",
    "# 'index' 열의 숫자 부분을 기준으로 정렬\n",
    "all_data['index_number'] = all_data['index'].str.extract(r'(\\d+)').astype(int)  # 숫자 부분 추출\n",
    "all_data = all_data.sort_values(by='index_number').drop(columns=['index_number']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 결과 파일로 저장\n",
    "all_data.to_csv(output_file, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(f\"파일이 생성되었습니다: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adressa_preprocess",
   "language": "python",
   "name": "adressa_preprocess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
